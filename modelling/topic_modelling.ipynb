{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals \n",
    "1. Perform topic modelling\n",
    "        a. perhaps create additional features for make up\n",
    "        b. create a useful comment search for users\n",
    "2. Word 2 Vec\n",
    "        a. To enhance performance of mapping questions/queries to comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import nltk\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfc = pd.read_csv('../data/comments_data.csv')\n",
    "text= dfc[['product_id', 'username', 'title', 'body', 'helpful' ,'not_helpful', 'star_count']]\n",
    "text = text.reset_index()\n",
    "text.columns = ['columnid'] + list(text.columns.values[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfp = pd.read_csv('../app/products.csv')\n",
    "dfu = pd.read_csv('../app/users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = text.join(dfu.set_index('username'), on='username')\n",
    "text = text.join(dfp.set_index('product_id'), on='product_id')\n",
    "text = text.drop(['username', 'product_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Text Cleaning\n",
    "- split to sentences\n",
    "- remove punctuation\n",
    "- lowercase\n",
    "- tokenize to words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text['text'] = text.body.str.lower()\n",
    "text = text[text.body.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = text.text.apply(sent_tokenize)\n",
    "df_sent = pd.concat([pd.DataFrame({'commentid': i, 'comment': x}) for i,x in enumerate(sentences)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sent.comment = df_sent.comment.str.replace('([\\:\\-\\.\\,\\;\\(\\)\\!])', ' ')\n",
    "df_sent.comment = df_sent.comment.str.strip()\n",
    "df_sent = df_sent[df_sent.comment.str.len() > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephinetirtanata/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "df_sent.loc[:, 'comment'] = df_sent.comment.str.replace(' (\\d+\\w+) ', ' ') # words that has numbers and letters\n",
    "df_sent.loc[:, 'comment'] = df_sent.comment.str.replace('(\\w*\\d+\\w*)', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(tf_v2.get_feature_names()) # from a previous tf vectorizer's feature names\n",
    "adjectives = [x[0] for x in tagged if x[1] in ['JJ', 'VBD', 'VBP', 'RB']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sent.to_pickle('df_sent.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = df_sent.sample(30000) # size of df to play around with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')  + adjectives +['love', 'recommend', 'amazing', 'foundation', 'lip', 'product','mascara', 'concealer', 'eyeshadow', 'stuff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_v = TfidfVectorizer(stop_words=sw, ngram_range=(1, 2), max_df=0.5)\n",
    "tf_v = tf_v.fit(sample.comment)\n",
    "tf = tf_v.transform(sample.comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_words(nmf, tf_vectorizer):\n",
    "    for topic_no, topic_vector in enumerate(nmf.components_):\n",
    "        print('Topic {}'.format(topic_no))\n",
    "        topic_weights = list(zip(tf_vectorizer.get_feature_names(), topic_vector))\n",
    "        sorted_topics = sorted(topic_weights, key=lambda x:x[1], reverse=True)\n",
    "        words = [x[0] for x in sorted_topics[:n_top_words]]\n",
    "        print(\", \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "color, match, color match, every color, color goes, pink, like color, dark, color payoff, every, payoff, color lasts, color lips, texture, color color, color texture, color light, color selection, lasting, selection\n",
      "Topic 1\n",
      "like, feel, feel like, look like, looks like, like wearing, wearing, feels, like color, wanted, feels like, wanted like, like matte, like look, face, better, would like, like one, like better, like powder\n",
      "Topic 2\n",
      "use, every, use every, every day, moisturizer, use moisturizer, use brush, eyes, eye, use use, use eyes, use anything, like use, face, would use, day use, liner, use face, use time, dark\n",
      "Topic 3\n",
      "coverage, gives, medium, medium coverage, gives coverage, light coverage, sheer, provides, coverage look, provides coverage, coverage without, sheer coverage, blends, cakey, build, feel, coverage light, amount, without, amount coverage\n",
      "Topic 4\n",
      "best, best used, one best, eyeliner, best eyeliner, hands, hands best, best part, best one, part, works best, best thing, best highlighter, best makeup, market, best palette, best best, best powder, thing, highlighter\n",
      "Topic 5\n",
      "colors, blend, colors blend, two colors, two, try colors, matte colors, palette colors, colors use, colors look, buying colors, colors palette, like colors, colors stay, stay, tone, pigmentation, one colors, three colors, colors work\n",
      "Topic 6\n",
      "look, makes look, look like, gives, made, cakey, made look, look cakey, gives look, coverage look, like look, lips look, face look, look feel, face, matte look, makeup look, dewy, dewy look, day look\n",
      "Topic 7\n",
      "would, anyone, would anyone, would purchase, thought, thought would, work, repurchase, would like, would repurchase, would work, would use, would would, coverage would, better, would try, something, like would, color would, would using\n",
      "Topic 8\n",
      "day, lasts, lasts day, every, every day, throughout day, throughout, end, stays day, end day, color lasts, stay, use every, stay day, work, night, lasts time, day night, looks lasts, day without\n",
      "Topic 9\n",
      "one, one best, products, like one, favorites, one favorites, one products, best one, one one, sephora, foundations, better, every, another, one star, star, palettes, lipsticks, find, use one\n",
      "Topic 10\n",
      "goes, way, goes way, bit, color goes, bit goes, goes stays, blends, goes blends, goes looks, goes lasts, goes like, thick, feels, goes color, like way, way goes, way feels, coverage goes, pricey\n",
      "Topic 11\n",
      "palette, palette colors, use palette, like palette, every, best palette, colors palette, matte palette, palette every, eye, shadows, one palette, wanted, eye palette, wanted palette, palette use, contour, create, palettes, contour palette\n",
      "Topic 12\n",
      "looks, looks like, feels, color looks, looks feels, face, feels looks, face looks, day looks, create, goes looks, use looks, looks cakey, blends, better, looks lasts, cakey, wearing, light looks, makeup looks\n",
      "Topic 13\n",
      "light, light coverage, medium, feels, light medium, feels light, tone, dark, color light, pink, light color, formula, coverage light, medium coverage, light pink, light light, face, light feeling, light hand, undertones\n",
      "Topic 14\n",
      "lips, feel, feels, lips feel, feels lips, makes lips, drying, color lips, gloss, lips look, drying lips, balm, moisturizing, feel lips, lips color, feeling, bit, feel like, keeps lips, hours\n",
      "Topic 15\n",
      "powder, setting, setting powder, set, set powder, like powder, face, use powder, brow, translucent, brow powder, liquid, finishing, coverage powder, finishing powder, translucent powder, best powder, powder used, face powder, loose\n",
      "Topic 16\n",
      "time, lasts time, every time, every, lasts, use time, compliments, purchasing, time use, time used, money, amount time, time purchasing, amount, time trying, stays time, next time, time using, trying, compliments time\n",
      "Topic 17\n",
      "price, price tag, tag, bit, price point, point, better, quality, size, amount, colors price, quality price, pay, sample, price opinion, opinion, price pay, stars, beat price, beat\n",
      "Topic 18\n",
      "works, better, combination, works best, one works, dark, works better, combination works, works wonders, wonders, eye, color works, use works, acne, matte works, works looks, circles, find, bronzer, acne prone\n",
      "Topic 19\n",
      "used, best used, years, used years, used use, since, better, used used, used since, time used, face, hands, times, powder used, used one, one used, liner, products, used like, eyes\n",
      "Topic 20\n",
      "try, must, wanted, reviews, wanted try, try colors, must try, another, would try, sample, sephora, try another, thought, something, try one, products, liner, going, brand, heard\n",
      "Topic 21\n",
      "stays, stays day, day, eyeliner, goes stays, color stays, hours, stays hours, liner, without, eyeliner stays, stays place, use stays, makeup stays, night, place, looks stays, stays time, covers, blends stays\n",
      "Topic 22\n",
      "looking, without, gives, without looking, something, looking like, looking something, coverage without, looking one, bit, coverage looking, dark, leaves, anyone, looking coverage, cakey, keeps, anyone looking, gives without, looking color\n",
      "Topic 23\n",
      "purchase, would purchase, sample, size, regret purchase, regret, sephora, purchase size, received, received sample, going, another, sample purchase, going purchase, gloss, purchase colors, purchase another, purchase color, purchase one, purchase purchase\n",
      "Topic 24\n",
      "makes, makes look, feel, makes lips, makes feel, feel like, eyes, pores, difference, makes eyes, makes makeup, like makes, makes face, lips feel, makes difference, better, face, dark, makes pores, look like\n",
      "Topic 25\n",
      "brush, use brush, blend, formula, comes, like brush, brush comes, blender, brush use, blends, though, application, must, liner, powder brush, face, sponge, work, end, fingers\n",
      "Topic 26\n",
      "matte, lasting, formula, like matte, matte look, matte colors, lipsticks, drying, matte formula, matte day, gives, matte lips, dries, matte drying, coverage matte, matte lipsticks, matte palette, matte matte, keeps, gives matte\n",
      "Topic 27\n",
      "using, years, using years, since, eyeliner, sample, since using, year, bare, months, liner, using year, couple, using since, minerals, bare minerals, used years, two, using months, without\n",
      "Topic 28\n",
      "makeup, face, must, wearing, makeup look, bag, makeup bag, wearing makeup, work, eye, hours, without, makes makeup, makeup day, remover, face makeup, makeup remover, products, feel, eye makeup\n",
      "Topic 29\n",
      "buying, every, sample, size, keep buying, buying size, keep, every penny, penny, buying colors, money, every day, going, received, sephora, every color, regret, time buying, received sample, regret buying\n"
     ]
    }
   ],
   "source": [
    "n_topics = 30\n",
    "n_top_words = 20\n",
    "nmf = NMF(n_components=n_topics).fit(tf)\n",
    "for topic_no, topic_vector in enumerate(nmf.components_):\n",
    "    print('Topic {}'.format(topic_no))\n",
    "    topic_weights = list(zip(tf_v.get_feature_names(), topic_vector))\n",
    "    sorted_topics = sorted(topic_weights, key=lambda x:x[1], reverse=True)\n",
    "    words = [x[0] for x in sorted_topics[:n_top_words]]\n",
    "    print(\", \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some of the sentences doesn't have topics\n",
    "remove_sentences = topic_probs.sum(axis=1) == 0\n",
    "# noting down the sentences that doesn't have topics because the cosine distance will always be zero for these.\n",
    "df_sent['no_topic'] = remove_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform on the whole corpus\n",
    "tfidf = tf_v.transform(df_sent.comment)\n",
    "topic_probs = nmf.transform(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save all of the data needed for comment search\n",
    "text.to_pickle('../data/text/comment_table.pkl')\n",
    "pickle.dump(tf_v, open('../data/text/tf_vectorizer.pkl', 'wb'))\n",
    "pickle.dump(nmf, open('../data/text/nmf.pkl', 'wb'))\n",
    "df_sent.to_pickle('../data/text/df_sent.pkl')\n",
    "pickle.dump(topic_probs, open('../data/text/topic_probs.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SystemError",
     "evalue": "Parent module '' not loaded, cannot perform relative import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-fe9b2343af24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mlibs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomment_finder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m: Parent module '' not loaded, cannot perform relative import"
     ]
    }
   ],
   "source": [
    "from ...libs import comment_finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('how', 'WRB'), ('where', 'WRB'), ('when', 'WRB'), ('why', 'WRB')]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(['how', 'where', 'when', 'why'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('good', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('formal', 'JJ'),\n",
       " ('events', 'NNS')]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag('is it good for formal events'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = df_sent.comment.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(tokens, size=100, window=5, min_count=1, workers=2,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(open('../data/word2vec.bin', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.delete_temporary_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mmuuuaaa', 0.26842302083969116),\n",
       " ('aarrgg', 0.24087241291999817),\n",
       " ('~sweetglamourmakeup', 0.2264493703842163),\n",
       " ('bummmmer', 0.22513119876384735),\n",
       " ('aagounthink', 0.22098058462142944),\n",
       " ('confounding', 0.2151275873184204),\n",
       " ('wronggggg', 0.20891711115837097),\n",
       " ('haaaaaaa', 0.2064480185508728),\n",
       " ('hibazmakeup', 0.20511563122272491),\n",
       " ('prrrrrrrrrrrrfection', 0.20327091217041016)]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(negative='good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEXT STEPS \n",
    "- do a tfidf with adjectives\n",
    "- get the JJ and with word2vec, find words that are close by\n",
    "- add this to the equation\n",
    "\n",
    "## For questions \n",
    "- do a pos tag, and take only JJ, NN and NNS\n",
    "- with NN and NNS, find comments with relevant topics\n",
    "- with JJ, find the words that are close and far away from the JJ with the word2vec model.\n",
    "- find a cosine similarity on the tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
